{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":190824229,"sourceType":"kernelVersion"}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%cd /kaggle/working\n!git clone --depth=1 https://github.com/ggerganov/llama.cpp.git\n%cd /kaggle/working/llama.cpp\n!sed -i 's|MK_LDFLAGS   += -lcuda|MK_LDFLAGS   += -L/usr/local/nvidia/lib64 -lcuda|' Makefile\n!LLAMA_CUDA=1 conda run -n base make -j > /dev/null","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-02T07:41:17.226627Z","iopub.execute_input":"2024-08-02T07:41:17.227159Z","iopub.status.idle":"2024-08-02T07:50:31.002968Z","shell.execute_reply.started":"2024-08-02T07:41:17.227114Z","shell.execute_reply":"2024-08-02T07:50:31.001790Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/working\nCloning into 'llama.cpp'...\nremote: Enumerating objects: 1063, done.\u001b[K\nremote: Counting objects: 100% (1063/1063), done.\u001b[K\nremote: Compressing objects: 100% (800/800), done.\u001b[K\nremote: Total 1063 (delta 252), reused 673 (delta 216), pack-reused 0\u001b[K\nReceiving objects: 100% (1063/1063), 17.67 MiB | 24.06 MiB/s, done.\nResolving deltas: 100% (252/252), done.\n/kaggle/working/llama.cpp\n","output_type":"stream"}]},{"cell_type":"code","source":"!python convert_hf_to_gguf.py /kaggle/input/finetune-llama3-part2/llama-3-8b-chat-doctor/ \\\n    --outfile /kaggle/working/llama-3-8b-chat-doctor.gguf \\\n    --outtype f16","metadata":{"execution":{"iopub.status.busy":"2024-08-02T07:52:12.151138Z","iopub.execute_input":"2024-08-02T07:52:12.151578Z","iopub.status.idle":"2024-08-02T07:55:21.757747Z","shell.execute_reply.started":"2024-08-02T07:52:12.151543Z","shell.execute_reply":"2024-08-02T07:55:21.755930Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\nWriting: 100%|██████████████████████████| 16.1G/16.1G [03:00<00:00, 89.2Mbyte/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}